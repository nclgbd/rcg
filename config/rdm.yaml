# * python main_rdm.py config-dir=$(pwd)/config/ config-name=rdm

experiment_name: rcg-experiments
defaults:
  - _self_
  - datasets: chest-xray14-dataset
  - mlflow: rcg-logger
  # overrides:
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

# Base configuration parameters
date: ${now:%Y-%m-%d}
device: 0
mode: diffusion
postfix: ""
random_state: 42
timestamp: ${now:%H-%M-%S}
use_transforms: true

# Resume from checkpoint
resume: ""
#
evaluate: false
# seed for reproducibility
seed: 42
# Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus
batch_size: ${datasets.dataloader.batch_size}
# Number of epochs to train
epochs: 100
# Number of images to generate
num_images: 3500
# Accumulate gradient iterations (for increasing the effective batch size under memory constraints)
accum_iter: 1
# Images input size
input_size: 256
# Config file
config: "/home/nicoleg/workspaces/rcg/config/rdm/mocov3vitb_simplemlp_l12_w1536_classcond.yaml"
#
# pretrained_rdm_cfg: "/home/nicoleg/workspaces/rcg/config/rdm/mocov3vitb_simplemlp_l12_w1536_classcond.yaml"
#
# pretrained_rdm_ckpt: "/home/nicoleg/workspaces/rcg/outputs/rdm/2024-02-01/16-00-35/outputs/checkpoint-last.pth"
#
class_cond: true
#
weight_decay: 0.05
# Learning rate
lr: null
# blr
blr: 0.00001
# min_lr
min_lr: 0.0
# cosine_lr
cosine_lr: true
# warmup_epochs
warmup_epochs: 0
# output_dir
output_dir: outputs
# log directory
log_dir: logs
# The starting epoch
start_epoch: 0
# The number of workers for the dataloader
num_workers: 24
# Whether to use pin_memory
pin_mem: true
# Distributed training
distributed: false
# The number of distributed processes
world_size: 1
# The rank of the current process
local_rank: -1
#
dist_on_itp: false
# url used to set up distributed training
dist_url: "env://"

hydra:
  job:
    chdir: true
  searchpath:
    - file:///home/nicoleg/workspaces/ResearchToolKit/configs
    - file:///home/nicoleg/workspaces/dissertation/configs
    - file:///home/nicoleg/workspaces/rcg/config
  sweep:
    dir: outputs/${hydra.job.config_name}/${date}/${timestamp}
    subdir: ${hydra.job.override_dirname}
  run:
    dir: outputs/${hydra.job.config_name}/${date}/${timestamp}
