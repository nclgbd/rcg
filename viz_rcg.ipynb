{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7665ccc-4b78-42d4-984f-be97e52e49f0",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f687283-ac25-443f-9404-86af90232665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import socket\n",
    "import time\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from rich import inspect\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# rcg\n",
    "from config import RCGConfiguration\n",
    "from engine_mage import gen_img\n",
    "from pixel_generator.mage import models_mage\n",
    "from rdm.util import instantiate_from_config\n",
    "import util.misc as misc\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rtk\n",
    "from rtk._datasets import create_transforms\n",
    "from rtk.config import *\n",
    "from rtk.datasets import instantiate_image_dataset\n",
    "from rtk.mlflow import prepare_mlflow\n",
    "from rtk.repl import prepare_console\n",
    "from rtk.utils import get_logger, hydra_instantiate, _strip_target\n",
    "\n",
    "ws, console = prepare_console(show_locals=False, _traceback=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3edecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_method_kwargs = {\"config_dir\": \"/home/nicoleg/workspaces/rcg/config/\"}\n",
    "overrides = [\n",
    "    \"device=3\",\n",
    "    \"datasets.preprocessing.positive_class=null\",\n",
    "    \"datasets.target=class_conditioned_labels\",\n",
    "    \"datasets/encoding=class-conditioned-encoding\",\n",
    "    \"datasets/transforms=rdm-transforms\",\n",
    "]\n",
    "config_name = \"rdm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf104abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "args: RCGConfiguration = set_hydra_configuration(\n",
    "    config_name,\n",
    "    ConfigurationInstance=RCGConfiguration,\n",
    "    init_method_kwargs=init_method_kwargs,\n",
    "    overrides=overrides,\n",
    ")\n",
    "console.print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4260cb2-dba5-4eb8-9796-9df6a3dd61e2",
   "metadata": {},
   "source": [
    "## Load pre-trained encoder, RDM and MAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c40a93-8fab-4804-8a91-1ee387da32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from rdm.models.diffusion.ddpm import RDM\n",
    "\n",
    "# Initialize RCG-L\n",
    "class_cond = False\n",
    "# rdm_ckpt_path = \"outputs/rdm/2024-02-01/16-00-35/outputs/checkpoint-last.pth\"\n",
    "rdm_ckpt_path = \"/home/nicoleg/workspaces/rcg/outputs/rdm/2024-02-01/16-00-35/outputs/checkpoint-0.pth\"\n",
    "rdm_cfg = \"config/rdm/mocov3vitb_simplemlp_l12_w1536_classcond.yaml\"\n",
    "model = models_mage.mage_vit_large_patch16(\n",
    "    mask_ratio_mu=0.75,\n",
    "    mask_ratio_std=0.25,\n",
    "    mask_ratio_min=0.5,\n",
    "    mask_ratio_max=1.0,\n",
    "    vqgan_ckpt_path=\"pretrained_enc_ckpts/vqgan_jax_strongaug.ckpt\",\n",
    "    use_rep=True,\n",
    "    rep_dim=256,\n",
    "    rep_drop_prob=0.1,\n",
    "    use_class_label=False,\n",
    "    pretrained_enc_arch=\"mocov3_vit_base\",\n",
    "    pretrained_enc_path=\"pretrained_enc_ckpts/mocov3/vitb.pth.tar\",\n",
    "    pretrained_enc_proj_dim=256,\n",
    "    pretrained_enc_withproj=True,\n",
    "    pretrained_rdm_ckpt=rdm_ckpt_path,\n",
    "    pretrained_rdm_cfg=rdm_cfg,\n",
    ")\n",
    "# config = OmegaConf.load(args.config)\n",
    "# model: RDM = instantiate_from_config(config.model)\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992f0ee-b13d-4842-9e9e-d7a1c4396e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(args.pretrained_rdm_ckpt, map_location='cpu')\n",
    "# model.load_state_dict(checkpoint['model'], strict=True)\n",
    "# model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e46dda-a436-48f6-8ffc-53b0d73af0f9",
   "metadata": {},
   "source": [
    "## Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rtk.datasets import set_labels_from_encoding\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "n_image_to_gen = 1\n",
    "rdm_steps = 250\n",
    "rdm_eta = 1.0\n",
    "mage_temp = 11.0\n",
    "mage_steps = 20\n",
    "cfg = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e10a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cfg = args.datasets\n",
    "labels = set_labels_from_encoding(args)\n",
    "class_encoding = {v: k for k, v in dataset_cfg.encoding.items()}\n",
    "class_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf0ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_torchimage(image: torch.Tensor):\n",
    "    image = torch.clamp(image, 0, 1)\n",
    "    image_np = image.detach().cpu().numpy().transpose([1, 2, 0])\n",
    "    image_np = Image.fromarray(np.uint8(image_np * 255))\n",
    "    display(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47de61-98e4-4311-980f-53ec7083c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = dataset_cfg.labels\n",
    "\n",
    "for class_label in class_encoding.keys():\n",
    "    label = class_encoding[class_label]\n",
    "    console.print(\"Generating: '{}'...\".format(label))\n",
    "    class_label = class_label * torch.ones(1).cuda().long()\n",
    "    for i in range(n_image_to_gen):\n",
    "        gen_images, lab = model.gen_image(\n",
    "            1,\n",
    "            num_iter=mage_steps,\n",
    "            choice_temperature=mage_temp,\n",
    "            sampled_rep=None,\n",
    "            rdm_steps=rdm_steps,\n",
    "            eta=rdm_eta,\n",
    "            cfg=cfg,\n",
    "            class_label=class_label,\n",
    "        )\n",
    "        visualize_scan(scan=gen_images[0], title=label)\n",
    "        # images.append(img)\n",
    "\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# for i, ax in enumerate(axs.flat):\n",
    "#     ax.imshow(images[i])\n",
    "#     ax.axis(\"off\")  # to hide the axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = instantiate_image_dataset(args)\n",
    "test_dataset = datasets[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba04518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(test_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import ThreadDataLoader\n",
    "\n",
    "loader = ThreadDataLoader(test_dataset, batch_size=1, num_workers=12, shuffle=True)\n",
    "iter_loader = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a3f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "scans, labels = next(iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bc90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scans.shape, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf093bbc-4001-48f4-9791-46ff6c8a676d",
   "metadata": {},
   "source": [
    "## GT Representation Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b2fd1-5065-4aa5-a35e-05b462565e85",
   "metadata": {},
   "source": [
    "### Generate Image from GT Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69b742-ec89-44db-b53c-b2d57a6a165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image_to_gen = 1\n",
    "rdm_steps = 250\n",
    "rdm_eta = 1.0\n",
    "mage_temp = 11.0\n",
    "mage_steps = 20\n",
    "cfg = 0.0\n",
    "\n",
    "images, _ = next(iter_loader)\n",
    "\n",
    "images = images.cuda()\n",
    "print(\"Ground Truth Image:\")\n",
    "plt.imshow(images[0], cmap=\"bone\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    mean = (\n",
    "        torch.Tensor([0.485, 0.456, 0.406])\n",
    "        .cuda()\n",
    "        .unsqueeze(0)\n",
    "        .unsqueeze(-1)\n",
    "        .unsqueeze(-1)\n",
    "    )\n",
    "    std = (\n",
    "        torch.Tensor([0.229, 0.224, 0.225])\n",
    "        .cuda()\n",
    "        .unsqueeze(0)\n",
    "        .unsqueeze(-1)\n",
    "        .unsqueeze(-1)\n",
    "    )\n",
    "    x_normalized = (images - mean) / std\n",
    "    x_normalized = torch.nn.functional.interpolate(x_normalized, 224, mode=\"bicubic\")\n",
    "    rep = model.pretrained_encoder.forward_features(x_normalized)\n",
    "    if model.pretrained_enc_withproj:\n",
    "        rep = model.pretrained_encoder.head(rep)\n",
    "    rep_std = torch.std(rep, dim=1, keepdim=True)\n",
    "    rep_mean = torch.mean(rep, dim=1, keepdim=True)\n",
    "    rep = (rep - rep_mean) / rep_std\n",
    "\n",
    "print(\"Reconstructed Images:\")\n",
    "recon_image_list = []\n",
    "for _ in range(n_image_to_gen):\n",
    "    recon_images, _ = model.gen_image(\n",
    "        12,\n",
    "        num_iter=mage_steps,\n",
    "        choice_temperature=mage_temp,\n",
    "        sampled_rep=rep,\n",
    "        rdm_steps=rdm_steps,\n",
    "        eta=rdm_eta,\n",
    "        cfg=cfg,\n",
    "        class_label=None,\n",
    "    )\n",
    "    visualize_scan(scan=recon_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588a7e4-9969-4684-b40f-9113e3467f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
